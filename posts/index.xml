<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Aniki's Blog</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/</link><description>Recent content in Posts on Aniki's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 02 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://whitewolf2000ani.github.io/AnikiBlogs/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>A VsCode extension for Mini-WDL</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/building-the-mini-wdl-vs-code-extension/</link><pubDate>Wed, 02 Apr 2025 00:00:00 +0000</pubDate><guid>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/building-the-mini-wdl-vs-code-extension/</guid><description>Introduction Creating a VS Code extension for Mini-WDL was an exciting journey filled with learning, debugging, and problem-solving. This blog details how I implemented syntax highlighting and language configuration for Mini-WDL, along with the challenges I facedâ€”particularly around marking comments correctlyâ€”and how I overcame them. Letâ€™s dive in!
1. Setting Up the Project Step 1: Followed the documentation VsCode To start, I used Yeomanâ€™s generator to create the basic structure of the VS Code extension:</description><content>&lt;h3 id="introduction">&lt;strong>Introduction&lt;/strong>&lt;/h3>
&lt;p>Creating a VS Code extension for Mini-WDL was an exciting journey filled with learning, debugging, and problem-solving. This blog details how I implemented syntax highlighting and language configuration for Mini-WDL, along with the challenges I facedâ€”particularly around marking comments correctlyâ€”and how I overcame them. Letâ€™s dive in!&lt;/p>
&lt;hr>
&lt;h3 id="1-setting-up-the-project">&lt;strong>1. Setting Up the Project&lt;/strong>&lt;/h3>
&lt;h4 id="step-1-followed-the-documentation-vscodehttpscodevisualstudiocomapiget-startedyour-first-extension">Step 1: Followed the documentation &lt;a href="https://code.visualstudio.com/api/get-started/your-first-extension">VsCode&lt;/a>&lt;/h4>
&lt;p>To start, I used Yeomanâ€™s generator to create the basic structure of the VS Code extension:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">mkdir mini-wdl-extension
cd mini-wdl-extension
npx yo code
&lt;/code>&lt;/pre>&lt;/div>&lt;p>During the prompts, I chose:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>TypeScript&lt;/strong> for type safety&lt;/li>
&lt;li>&lt;strong>No bundler&lt;/strong> for simplicity&lt;/li>
&lt;li>&lt;strong>npm&lt;/strong> as the package manager&lt;/li>
&lt;/ul>
&lt;p>This generated a project structure with files like &lt;code>extension.ts&lt;/code>, &lt;code>package.json&lt;/code>, and &lt;code>.vscode/launch.json&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>Folder Structure, we need to create a syntaxes directory mentioned.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-JSON" data-lang="JSON">&lt;span style="color:#960050;background-color:#1e0010">mini-wdl-extension/&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">.vscode/&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">VS&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Code-specific&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">settings&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”‚&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">launch.json&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Debug&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">configuration&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">the&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”‚&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">â””â”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">tasks.json&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Task&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">runner&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">configuration&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">src/&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">VS&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Code&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">source&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">files&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”‚&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension.ts&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Main&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">entry&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">point&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">the&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">VS&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Code&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”‚&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">server.ts&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Language&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">client&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">setup&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">connecting&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">to&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">the&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">server&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">syntaxes/&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">TextMate&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">grammar&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">syntax&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">highlighting&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”‚&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">â””â”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">mini-wdl.tmLanguage.json&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Syntax&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">highlighting&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">rules&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Mini-WDL&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">language-configuration.json&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Language-specific&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">editor&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">configurations&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">(e.g.,&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">comments,&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">brackets)&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">package.json&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">VS&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Code&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">metadata&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">and&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">dependencies&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">tsconfig.json&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">TypeScript&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">configuration&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">the&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â”œâ”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">README.md&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Documentation&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">for&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">your&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">extension&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">(this&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">file)&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">â””â”€â”€&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">node_modules/&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">Node.js&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">dependencies&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">(created&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">after&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">`npm&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">install`)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h3 id="2-adding-syntax-highlighting">&lt;strong>2. Adding Syntax Highlighting&lt;/strong>&lt;/h3>
&lt;h4 id="step-2-creating-textmate-grammar">&lt;strong>Step 2: Creating TextMate Grammar&lt;/strong>&lt;/h4>
&lt;p>I created a TextMate grammar file (&lt;code>syntaxes/mini-wdl.tmLanguage.json&lt;/code>) to define syntax highlighting rules for WDL keywords, strings, and comments.&lt;/p>
&lt;p>Hereâ€™s what the grammar looked like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Mini WDL&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;scopeName&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;source.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;fileTypes&amp;#34;&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;wdl&amp;#34;&lt;/span>],
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#keywords&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#comments&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#strings&amp;#34;&lt;/span> }
],
&lt;span style="color:#f92672">&amp;#34;repository&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;keywords&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;keyword.control.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\b(task|workflow|input|output|command)\\b&amp;#34;&lt;/span>
}
]
},
&lt;span style="color:#f92672">&amp;#34;comments&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;comment.line.number-sign.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#.*$&amp;#34;&lt;/span>
}
]
},
&lt;span style="color:#f92672">&amp;#34;strings&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;string.quoted.double.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;begin&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\&amp;#34;&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;end&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\&amp;#34;&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;constant.character.escape.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\\\.&amp;#34;&lt;/span>
}
]
}
]
}
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h3 id="3-configuring-language-basics">&lt;strong>3. Configuring Language Basics&lt;/strong>&lt;/h3>
&lt;h4 id="step-3-language-configuration-file">&lt;strong>Step 3: Language Configuration File&lt;/strong>&lt;/h4>
&lt;p>I added a language configuration file (&lt;code>language-configuration.json&lt;/code>) to define comment styles, brackets, and auto-closing pairs:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;comments&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;lineComment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#&amp;#34;&lt;/span>
},
&lt;span style="color:#f92672">&amp;#34;brackets&amp;#34;&lt;/span>: [
[&lt;span style="color:#e6db74">&amp;#34;{&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;}&amp;#34;&lt;/span>],
[&lt;span style="color:#e6db74">&amp;#34;[&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;]&amp;#34;&lt;/span>],
[&lt;span style="color:#e6db74">&amp;#34;(&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;)&amp;#34;&lt;/span>]
],
&lt;span style="color:#f92672">&amp;#34;autoClosingPairs&amp;#34;&lt;/span>: [
{ &lt;span style="color:#f92672">&amp;#34;open&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;{&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;close&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;}&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;open&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;[&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;close&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;]&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;open&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\&amp;#34;&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;close&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\&amp;#34;&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;open&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#39;&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;close&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#39;&amp;#34;&lt;/span> }
]
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This ensured that typing &lt;code>{&lt;/code> or &lt;code>&amp;quot;&lt;/code> would automatically close with &lt;code>}&lt;/code> or &lt;code>&amp;quot;&lt;/code>.&lt;/p>
&lt;hr>
&lt;h3 id="4-challenges-faced">&lt;strong>4. Challenges Faced&lt;/strong>&lt;/h3>
&lt;h4 id="problem-comments-not-getting-marked-correctly-and-the-keywords-didnt-highlight">&lt;strong>Problem: Comments Not Getting Marked Correctly and the keywords didn&amp;rsquo;t highlight&lt;/strong>&lt;/h4>
&lt;p>Initially, comments were not being detected or highlighted properly in &lt;code>.wdl&lt;/code> files. This was frustrating because comments are critical for workflow readability.
&lt;img src="https://whitewolf2000ani.github.io/AnikiBlogs/images/Screenshot_2025-04-06_131443_1.png" alt="Image Description">
&lt;em>The comments, keywords were not hihglighted as you can see in this image.&lt;/em>&lt;/p>
&lt;h4 id="root-cause">&lt;strong>Root Cause:&lt;/strong>&lt;/h4>
&lt;p>The issue was with my regex pattern for comments in the TextMate grammar file. My initial implementation only matched simple &lt;code>#&lt;/code> comments but failed when there were special characters or escaped sequences.&lt;/p>
&lt;h4 id="solution">&lt;strong>Solution:&lt;/strong>&lt;/h4>
&lt;p>I updated the regex to handle edge cases like escaped characters within comments:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;comment.line.number-sign.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#.*$&amp;#34;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Update the &lt;code>mini-wdl.tmLanguge.json&lt;/code> to make it more robust&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-JSON" data-lang="JSON">{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Mini WDL&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;scopeName&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;source.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;fileTypes&amp;#34;&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;wdl&amp;#34;&lt;/span>],
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#keywords&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#strings&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#comments&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#types&amp;#34;&lt;/span> },
{ &lt;span style="color:#f92672">&amp;#34;include&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#variables&amp;#34;&lt;/span> }
],
&lt;span style="color:#f92672">&amp;#34;repository&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;keywords&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;keyword.control.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\b(task|workflow|call|if|else|then|scatter|input|output|command|meta|parameter_meta|runtime)\\b&amp;#34;&lt;/span>
}
]
},
&lt;span style="color:#f92672">&amp;#34;strings&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;string.quoted.double.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;begin&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\&amp;#34;&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;end&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\&amp;#34;&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;constant.character.escape.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\\\.&amp;#34;&lt;/span>
}
]
},
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;string.quoted.single.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;begin&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#39;&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;end&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#39;&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;constant.character.escape.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\\\.&amp;#34;&lt;/span>
}
]
}
]
},
&lt;span style="color:#f92672">&amp;#34;comments&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;comment.line.number-sign&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;#.*$&amp;#34;&lt;/span>
}
]
},
&lt;span style="color:#f92672">&amp;#34;types&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;storage.type.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\b(Boolean|Int|Float|String|File|Array|Map|Object|Pair)\\b&amp;#34;&lt;/span>
}
]
},
&lt;span style="color:#f92672">&amp;#34;variables&amp;#34;&lt;/span>: {
&lt;span style="color:#f92672">&amp;#34;patterns&amp;#34;&lt;/span>: [
{
&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;variable.other.mini-wdl&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;match&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;\\b[a-zA-Z][a-zA-Z0-9_]*\\b&amp;#34;&lt;/span>
}
]
}
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Additionally, I verified token scopes using VS Codeâ€™s Developer Tools: (==This helped me a lot==)&lt;/p>
&lt;ol>
&lt;li>Press &lt;code>Ctrl+Shift+P&lt;/code> (or &lt;code>Cmd+Shift+P&lt;/code> on macOS).&lt;/li>
&lt;li>Type â€œDeveloper: Inspect Editor Tokens and Scopes.â€&lt;/li>
&lt;li>Click on different parts of your code to see applied tokens.&lt;/li>
&lt;/ol>
&lt;p>This helped me confirm that comments were now being marked correctly!
&lt;img src="https://whitewolf2000ani.github.io/AnikiBlogs/images/Pasted_image_20250408112347.png" alt="Image Description">
&lt;em>And then we got this&lt;/em> ðŸ˜–ðŸ˜ &lt;em>everything came to light&lt;/em>&lt;/p>
&lt;hr>
&lt;h3 id="5-testing-the-extension">&lt;strong>5. Testing the Extension&lt;/strong>&lt;/h3>
&lt;h4 id="step-4-creating-a-test-file">&lt;strong>Step 4: Creating a Test File&lt;/strong>&lt;/h4>
&lt;p>I created a test file (&lt;code>test.wdl&lt;/code>) to verify syntax highlighting and language configuration:&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl"># This is a test WDL workflow
task hello {
input {
String name
Int count = 3
}
command {
echo &amp;quot;Hello ${name}&amp;quot;
echo &amp;quot;Count: ${count}&amp;quot;
}
}
workflow test_workflow {
input {
String person_name = &amp;quot;World&amp;quot;
}
call hello {
input:
name = person_name
}
}
&lt;/code>&lt;/pre>&lt;h4 id="step-5-running-the-extension">&lt;strong>Step 5: Running the Extension&lt;/strong>&lt;/h4>
&lt;ol>
&lt;li>Compile the extension:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm run compile
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>Launch in debug mode (or press F5 in VS Code).&lt;/li>
&lt;/ol>
&lt;p>When I opened &lt;code>test.wdl&lt;/code>, keywords like &lt;code>task&lt;/code>, &lt;code>workflow&lt;/code>, and &lt;code>input&lt;/code> were correctly highlighted, and comments were marked as expected.&lt;/p>
&lt;hr>
&lt;h3 id="6-lessons-learned">&lt;strong>6. Lessons Learned&lt;/strong>&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>Regex Debugging:&lt;/strong> Writing robust regex patterns requires testing edge cases (e.g., escaped characters). Tools like VS Codeâ€™s scope inspector are invaluable.&lt;/li>
&lt;li>&lt;strong>Language Configuration:&lt;/strong> Small details like auto-closing pairs significantly improve usability.&lt;/li>
&lt;li>&lt;strong>Testing Matters:&lt;/strong> Creating test files early helps catch issues before they become blockers.&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h3 id="7-conclusion">&lt;strong>7. Conclusion&lt;/strong>&lt;/h3>
&lt;p>Building this Mini-WDL extension taught me how language tooling works under the hoodâ€”from defining syntax rules to debugging token scopes. While solving issues like comment detection was challenging, it reinforced my understanding of TextMate grammars and VS Codeâ€™s API.
This project is just the beginning! With basic syntax highlighting and language configuration in place, Iâ€™m excited to explore advanced features like semantic highlighting and LSP integration in the next blog.
A blog on working with WDL is also coming up!
If youâ€™re interested in building your own extensions or contributing to WDL tooling, check out my GitHub repository: &lt;a href="https://github.com/whitewolf2000ani/Mini-WDL">github.com/whitewolf2000ani/Mini-WDL&lt;/a>.&lt;/p></content></item><item><title>What I learned about WDL</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/wdl-the-workflow-description-language-powering-bioinformatics/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/wdl-the-workflow-description-language-powering-bioinformatics/</guid><description>What is WDL? The Workflow Description Language (WDL) is an open-source language designed to simplify complex computational workflows, particularly in genomics and bioinformatics. Developed by the Broad Institute and maintained by the OpenWDL community, WDL allows scientists to define analysis pipelines in a human-readable format.
Why It Matters:
Standardizes workflow definitions across platforms Enables reproducibility in scientific research Simplifies scaling from laptops to cloud environments WDL Syntax: A Step-by-Step Breakdown Letâ€™s dissect a simple WDL workflow to understand its structure.</description><content>&lt;hr>
&lt;h3 id="what-is-wdl">&lt;strong>What is WDL?&lt;/strong>&lt;/h3>
&lt;p>The &lt;strong>Workflow Description Language (WDL)&lt;/strong> is an open-source language designed to simplify complex computational workflows, particularly in genomics and bioinformatics. Developed by the Broad Institute and maintained by the OpenWDL community, WDL allows scientists to define analysis pipelines in a human-readable format.&lt;/p>
&lt;p>&lt;strong>Why It Matters&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Standardizes workflow definitions across platforms&lt;/li>
&lt;li>Enables reproducibility in scientific research&lt;/li>
&lt;li>Simplifies scaling from laptops to cloud environments&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="wdl-syntax-a-step-by-step-breakdown">&lt;strong>WDL Syntax: A Step-by-Step Breakdown&lt;/strong>&lt;/h3>
&lt;p>Letâ€™s dissect a simple WDL workflow to understand its structure.&lt;/p>
&lt;h4 id="example-workflow">&lt;strong>Example Workflow&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">version 1.2 # Modern WDL version
task say_hello {
input {
String greeting
String name
}
command &amp;lt;&amp;lt;&amp;lt;;
echo &amp;quot;~{greeting}, ~{name}!&amp;quot;
&amp;gt;&amp;gt;&amp;gt;;
output {
String message = read_string(stdout())
}
requirements {
container: &amp;quot;ubuntu:latest&amp;quot;
}
}
workflow main {
input {
String name
Boolean is_pirate = false
}
Array[String] greetings = select_all([
&amp;quot;Hello&amp;quot;,
&amp;quot;Hallo&amp;quot;,
&amp;quot;Hej&amp;quot;,
(
if is_pirate
then &amp;quot;Ahoy&amp;quot;
else None
),
])
scatter (greeting in greetings) {
call say_hello {
input:
greeting = greeting,
name = name
}
}
output {
Array[String] messages = say_hello.message
}
}
&lt;/code>&lt;/pre>&lt;hr>
&lt;h3 id="line-by-line-breakdown">&lt;strong>Line-by-Line Breakdown&lt;/strong>&lt;/h3>
&lt;h4 id="1-version-declaration">&lt;strong>1. Version Declaration&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">version 1.2
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>New in 1.2&lt;/strong>: Adds features like &lt;code>select_all()&lt;/code> and improved error handling.&lt;/li>
&lt;li>&lt;strong>Best Practice&lt;/strong>: Always declare versions explicitly for compatibility.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="2-task-definition">&lt;strong>2. Task Definition&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">task say_hello {
input {
String greeting
String name
}
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Input Parameters&lt;/strong>: Declares two required inputs for personalization.&lt;/li>
&lt;li>&lt;strong>Flexibility&lt;/strong>: Tasks can be reused across workflows with different inputs.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="3-command-section-heredoc-syntax">&lt;strong>3. Command Section (Heredoc Syntax)&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">command &amp;gt;&amp;gt;&amp;gt;;
echo &amp;quot;~{greeting}, ~{name}!&amp;quot;
&amp;lt;&amp;lt;&amp;lt;;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>&lt;code>&amp;lt;&amp;lt;&amp;lt;;&lt;/code> Syntax&lt;/strong>: Allows multi-line commands without escaping quotes.&lt;/li>
&lt;li>&lt;strong>Variable Substitution&lt;/strong>: &lt;code>~{}&lt;/code> injects WDL variables into shell commands.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="4-output-declaration">&lt;strong>4. Output Declaration&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">output {
String message = read_string(stdout())
}
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>&lt;code>read_string()&lt;/code>&lt;/strong>: Built-in function captures command output.&lt;/li>
&lt;li>&lt;strong>Type Safety&lt;/strong>: Explicit &lt;code>String&lt;/code> type ensures data consistency.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="5-runtime-requirements">&lt;strong>5. Runtime Requirements&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">requirements {
container: &amp;quot;ubuntu:latest&amp;quot;
}
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Reproducibility&lt;/strong>: Uses Docker containers for consistent environments.&lt;/li>
&lt;li>&lt;strong>Alternatives&lt;/strong>: Can specify CPU/memory constraints instead.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="6-workflow-inputs">&lt;strong>6. Workflow Inputs&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">input {
String name
Boolean is_pirate = false
}
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Default Values&lt;/strong>: &lt;code>is_pirate&lt;/code> is optional (defaults to &lt;code>false&lt;/code>).&lt;/li>
&lt;li>&lt;strong>Runtime Flexibility&lt;/strong>: Users can override defaults when executing.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="7-array-with-conditional-logic">&lt;strong>7. Array with Conditional Logic&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">Array[String] greetings = select_all([
&amp;quot;Hello&amp;quot;,
&amp;quot;Hallo&amp;quot;,
&amp;quot;Hej&amp;quot;,
(if is_pirate then &amp;quot;Ahoy&amp;quot; else None),
])
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>&lt;code>select_all()&lt;/code>&lt;/strong>: Filters out &lt;code>None&lt;/code> values, creating a clean array.&lt;/li>
&lt;li>&lt;strong>Conditional Expression&lt;/strong>: Adds &amp;ldquo;Ahoy&amp;rdquo; only if &lt;code>is_pirate&lt;/code> is &lt;code>true&lt;/code>.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="8-parallel-execution">&lt;strong>8. Parallel Execution&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">scatter (greeting in greetings) {
call say_hello { input: greeting, name }
}
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Scatter/Gather&lt;/strong>: Runs &lt;code>say_hello&lt;/code> in parallel for each greeting.&lt;/li>
&lt;li>&lt;strong>Cloud Optimization&lt;/strong>: Automatically scales on distributed systems.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="9-workflow-output">&lt;strong>9. Workflow Output&lt;/strong>&lt;/h4>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">output {
Array[String] messages = say_hello.message
}
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Aggregation&lt;/strong>: Collects outputs from all parallel tasks.&lt;/li>
&lt;li>&lt;strong>Downstream Use&lt;/strong>: These messages could feed into another workflow.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="key-wdl-12-features-demonstrated">&lt;strong>Key WDL 1.2 Features Demonstrated&lt;/strong>&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>Conditional Arrays&lt;/strong>:&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">(if is_pirate then &amp;quot;Ahoy&amp;quot; else None)
&lt;/code>&lt;/pre>&lt;pre>&lt;code>- Enables dynamic workflow configurations based on inputs.
&lt;/code>&lt;/pre>
&lt;ol start="2">
&lt;li>&lt;strong>Scatter Parallelization&lt;/strong>:&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">scatter (greeting in greetings) { ... }
&lt;/code>&lt;/pre>&lt;pre>&lt;code>- Simplifies parallel processing of large datasets.
&lt;/code>&lt;/pre>
&lt;ol start="3">
&lt;li>&lt;strong>Type-Safe Outputs&lt;/strong>:&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">Array[String] messages = say_hello.message
&lt;/code>&lt;/pre>&lt;pre>&lt;code>- Ensures data integrity between workflow steps.
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h3 id="running-the-workflow">&lt;strong>Running the Workflow&lt;/strong>&lt;/h3>
&lt;p>&lt;strong>Input JSON&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;main.name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Dave&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;main.is_pirate&amp;#34;&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Expected Output&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;main.messages&amp;#34;&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;Hello, Dave!&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;Hallo, Dave!&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;Hej, Dave!&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;Ahoy, Dave!&amp;#34;&lt;/span>]
}
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h3 id="getting-started-with-wdl">&lt;strong>Getting Started with WDL&lt;/strong>&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>Install a WDL Runner&lt;/strong>:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># For MiniWDL (used in our project): &lt;/span>
pip install miniwdl
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>&lt;strong>Write Your First Workflow&lt;/strong>:&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code class="language-wdl" data-lang="wdl">version 1.0
workflow hello_wdl {
call say_hello
output {
String message = &amp;quot;Workflow completed!&amp;quot;
}
}
task say_hello {
command { echo &amp;quot;Hello, WDL!&amp;quot; }
}
&lt;/code>&lt;/pre>&lt;ol start="3">
&lt;li>&lt;strong>Run It&lt;/strong>:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">miniwdl run hello.wdl
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h3 id="conclusion">&lt;strong>Conclusion&lt;/strong>&lt;/h3>
&lt;p>By learning WDL, I gained the foundation needed to build tools around WDL, which aims to make workflow development even more intuitive.&lt;/p>
&lt;p>&lt;strong>Resources&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.openwdl.org/">OpenWDL Documentation&lt;/a> -&amp;gt; The documentation is really good to understand WDL.&lt;/li>
&lt;li>&lt;a href="https://docs.openwdl.org/getting-started/quickstart.html">WDL Quickstart Guide&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>ASTx to Python Mapping Strategy</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/astx-python-ast-mapping/</link><pubDate>Mon, 24 Mar 2025 00:00:00 +0000</pubDate><guid>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/astx-python-ast-mapping/</guid><description>1. Expression Node Mapping ASTx BinaryOp â†’ Python ast.BinOp ASTx Structure:
BinaryOp( lhs: Expr, rhs: Expr, op: BinaryOpKind ) Python AST Equivalent:
ast.BinOp( left: ast.expr, op: operator, right: ast.expr ) Conversion Logic:
# Operator mapping table OP_MAP = { BinaryOpKind.add: ast.Add(), BinaryOpKind.sub: ast.Sub(), BinaryOpKind.mul: ast.Mult() } @dispatch def visit(self, node: BinaryOp) -&amp;gt; ast.BinOp: return ast.BinOp( left=self.visit(node.lhs), op=OP_MAP[node.op], right=self.visit(node.rhs) ) 2. Statement Node Mapping ASTx DeleteStmt â†’ Python ast.Delete ASTx Structure:</description><content>&lt;hr>
&lt;h2 id="1-expression-node-mapping">1. Expression Node Mapping&lt;/h2>
&lt;h3 id="astx-binaryop--python-astbinop">ASTx BinaryOp â†’ Python ast.BinOp&lt;/h3>
&lt;p>&lt;strong>ASTx Structure&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">BinaryOp(
lhs: Expr,
rhs: Expr,
op: BinaryOpKind
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Python AST Equivalent&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">ast&lt;span style="color:#f92672">.&lt;/span>BinOp(
left: ast&lt;span style="color:#f92672">.&lt;/span>expr,
op: operator,
right: ast&lt;span style="color:#f92672">.&lt;/span>expr
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Conversion Logic&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># Operator mapping table&lt;/span>
OP_MAP &lt;span style="color:#f92672">=&lt;/span> {
BinaryOpKind&lt;span style="color:#f92672">.&lt;/span>add: ast&lt;span style="color:#f92672">.&lt;/span>Add(),
BinaryOpKind&lt;span style="color:#f92672">.&lt;/span>sub: ast&lt;span style="color:#f92672">.&lt;/span>Sub(),
BinaryOpKind&lt;span style="color:#f92672">.&lt;/span>mul: ast&lt;span style="color:#f92672">.&lt;/span>Mult()
}
&lt;span style="color:#a6e22e">@dispatch&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">visit&lt;/span>(self, node: BinaryOp) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>BinOp:
&lt;span style="color:#66d9ef">return&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>BinOp(
left&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>visit(node&lt;span style="color:#f92672">.&lt;/span>lhs),
op&lt;span style="color:#f92672">=&lt;/span>OP_MAP[node&lt;span style="color:#f92672">.&lt;/span>op],
right&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>visit(node&lt;span style="color:#f92672">.&lt;/span>rhs)
)
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="2-statement-node-mapping">2. Statement Node Mapping&lt;/h2>
&lt;h3 id="astx-deletestmt--python-astdelete">ASTx DeleteStmt â†’ Python ast.Delete&lt;/h3>
&lt;p>&lt;strong>ASTx Structure&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">DeleteStmt(
value: Iterable[Identifier]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Python AST Equivalent&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">ast&lt;span style="color:#f92672">.&lt;/span>Delete(
targets: list[ast&lt;span style="color:#f92672">.&lt;/span>expr]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Conversion Logic&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#a6e22e">@dispatch&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">visit&lt;/span>(self, node: DeleteStmt) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>Delete:
&lt;span style="color:#66d9ef">return&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>Delete(
targets&lt;span style="color:#f92672">=&lt;/span>[ast&lt;span style="color:#f92672">.&lt;/span>Name(id&lt;span style="color:#f92672">=&lt;/span>ident&lt;span style="color:#f92672">.&lt;/span>value, ctx&lt;span style="color:#f92672">=&lt;/span>ast&lt;span style="color:#f92672">.&lt;/span>Del())
&lt;span style="color:#66d9ef">for&lt;/span> ident &lt;span style="color:#f92672">in&lt;/span> node&lt;span style="color:#f92672">.&lt;/span>value]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Special Handling&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Convert ASTx Identifiers to Python Name nodes with Del context&lt;/li>
&lt;li>Handle nested deletion targets (e.g., del x)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="3-declaration-mapping">3. Declaration Mapping&lt;/h2>
&lt;h3 id="astx-variabledeclaration--python-astassign">ASTx VariableDeclaration â†’ Python ast.Assign&lt;/h3>
&lt;p>&lt;strong>ASTx Structure&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">VariableDeclaration(
name: str,
type_: DataType,
value: Expr
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Python AST Equivalent&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">ast&lt;span style="color:#f92672">.&lt;/span>Assign(
targets: list[ast&lt;span style="color:#f92672">.&lt;/span>Name],
value: ast&lt;span style="color:#f92672">.&lt;/span>expr
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Conversion Logic&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#a6e22e">@dispatch&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">visit&lt;/span>(self, node: VariableDeclaration) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>Assign:
&lt;span style="color:#66d9ef">return&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>Assign(
targets&lt;span style="color:#f92672">=&lt;/span>[ast&lt;span style="color:#f92672">.&lt;/span>Name(id&lt;span style="color:#f92672">=&lt;/span>node&lt;span style="color:#f92672">.&lt;/span>name, ctx&lt;span style="color:#f92672">=&lt;/span>ast&lt;span style="color:#f92672">.&lt;/span>Store())],
value&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>visit(node&lt;span style="color:#f92672">.&lt;/span>value)
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Edge Cases&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Support for multiple assignment targets&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="4-control-flow-mapping">4. Control Flow Mapping&lt;/h2>
&lt;h3 id="astx-ifstmt--python-astif">ASTx IfStmt â†’ Python ast.If&lt;/h3>
&lt;p>&lt;strong>ASTx Structure&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">IfStmt(
condition: Expr,
then_block: list[Statement],
else_block: list[Statement]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Python AST Equivalent&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">ast&lt;span style="color:#f92672">.&lt;/span>If(
test: ast&lt;span style="color:#f92672">.&lt;/span>expr,
body: list[ast&lt;span style="color:#f92672">.&lt;/span>stmt],
orelse: list[ast&lt;span style="color:#f92672">.&lt;/span>stmt]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Conversion Logic&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#a6e22e">@dispatch&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">visit&lt;/span>(self, node: IfStmt) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>If:
&lt;span style="color:#66d9ef">return&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>If(
test&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>visit(node&lt;span style="color:#f92672">.&lt;/span>condition),
body&lt;span style="color:#f92672">=&lt;/span>[self&lt;span style="color:#f92672">.&lt;/span>visit(stmt) &lt;span style="color:#66d9ef">for&lt;/span> stmt &lt;span style="color:#f92672">in&lt;/span> node&lt;span style="color:#f92672">.&lt;/span>then_block],
orelse&lt;span style="color:#f92672">=&lt;/span>[self&lt;span style="color:#f92672">.&lt;/span>visit(stmt) &lt;span style="color:#66d9ef">for&lt;/span> stmt &lt;span style="color:#f92672">in&lt;/span> node&lt;span style="color:#f92672">.&lt;/span>else_block]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Special Handling&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Empty else block conversion&lt;/li>
&lt;li>Nested if-elif-else structures&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="5-function-definition-mapping">5. Function Definition Mapping&lt;/h2>
&lt;h3 id="astx-functiondef--python-astfunctiondef">ASTx FunctionDef â†’ Python ast.FunctionDef&lt;/h3>
&lt;p>&lt;strong>ASTx Structure&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">FunctionDef(
name: str,
args: Arguments,
return_type: DataType,
body: list[Statement]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Python AST Equivalent&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">ast&lt;span style="color:#f92672">.&lt;/span>FunctionDef(
name: str,
args: ast&lt;span style="color:#f92672">.&lt;/span>arguments,
body: list[ast&lt;span style="color:#f92672">.&lt;/span>stmt],
decorator_list: list[ast&lt;span style="color:#f92672">.&lt;/span>expr]
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Conversion Logic&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#a6e22e">@dispatch&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">visit&lt;/span>(self, node: FunctionDef) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>FunctionDef:
&lt;span style="color:#66d9ef">return&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>FunctionDef(
name&lt;span style="color:#f92672">=&lt;/span>node&lt;span style="color:#f92672">.&lt;/span>name,
args&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>visit(node&lt;span style="color:#f92672">.&lt;/span>args),
body&lt;span style="color:#f92672">=&lt;/span>[self&lt;span style="color:#f92672">.&lt;/span>visit(stmt) &lt;span style="color:#66d9ef">for&lt;/span> stmt &lt;span style="color:#f92672">in&lt;/span> node&lt;span style="color:#f92672">.&lt;/span>body],
decorator_list&lt;span style="color:#f92672">=&lt;/span>[],
returns&lt;span style="color:#f92672">=&lt;/span>ast&lt;span style="color:#f92672">.&lt;/span>Name(id&lt;span style="color:#f92672">=&lt;/span>node&lt;span style="color:#f92672">.&lt;/span>return_type&lt;span style="color:#f92672">.&lt;/span>__name__)
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Special Handling&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Argument type annotations&lt;/li>
&lt;li>Return type declarations&lt;/li>
&lt;li>Decorator support&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="6-context-management-strategy">6. Context Management Strategy&lt;/h2>
&lt;p>&lt;strong>ASTx Context&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">Variable(
name: str,
type_: DataType
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Python Context Handling&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">ContextManager&lt;/span>:
&lt;span style="color:#66d9ef">def&lt;/span> __init__(self):
self&lt;span style="color:#f92672">.&lt;/span>scope_stack &lt;span style="color:#f92672">=&lt;/span> [{}]
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">add_variable&lt;/span>(self, name: str, node: ast&lt;span style="color:#f92672">.&lt;/span>AST):
self&lt;span style="color:#f92672">.&lt;/span>scope_stack[&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>][name] &lt;span style="color:#f92672">=&lt;/span> node
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_variable&lt;/span>(self, name: str) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>expr:
&lt;span style="color:#66d9ef">for&lt;/span> scope &lt;span style="color:#f92672">in&lt;/span> reversed(self&lt;span style="color:#f92672">.&lt;/span>scope_stack):
&lt;span style="color:#66d9ef">if&lt;/span> name &lt;span style="color:#f92672">in&lt;/span> scope:
&lt;span style="color:#66d9ef">return&lt;/span> scope[name]
&lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">NameError&lt;/span>(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Variable &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>name&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> not defined&amp;#34;&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="validation-strategy">Validation Strategy&lt;/h2>
&lt;ul>
&lt;li>Round Trip Validation&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">test_binary_op_roundtrip&lt;/span>():
&lt;span style="color:#75715e"># ASTx â†’ Python AST â†’ Python code&lt;/span>
astx_node &lt;span style="color:#f92672">=&lt;/span> BinaryOp(LiteralInt32(&lt;span style="color:#ae81ff">2&lt;/span>), LiteralInt32(&lt;span style="color:#ae81ff">3&lt;/span>), BinaryOpKind&lt;span style="color:#f92672">.&lt;/span>add)
transpiler &lt;span style="color:#f92672">=&lt;/span> ASTxPythonASTTranspiler()
py_ast &lt;span style="color:#f92672">=&lt;/span> transpiler&lt;span style="color:#f92672">.&lt;/span>visit(astx_node)
&lt;span style="color:#75715e"># Generate Python code&lt;/span>
code &lt;span style="color:#f92672">=&lt;/span> ast&lt;span style="color:#f92672">.&lt;/span>unparse(py_ast)
&lt;span style="color:#66d9ef">assert&lt;/span> code &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;(2 + 3)&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></content></item><item><title>Implementing Open LLM Models with JAX and Flax</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/implementing-open-llm-models-with-jax-and-flax/</link><pubDate>Fri, 21 Mar 2025 00:00:00 +0000</pubDate><guid>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/implementing-open-llm-models-with-jax-and-flax/</guid><description>Before diving into the implementation details, I want to summarize our approach: we&amp;rsquo;ll be creating JAX/Flax implementations of popular open-source LLM architectures, documenting everything thoroughly, and providing clear notebooks to demonstrate their usage.
Project Overview JAX, combined with Flax, provides a powerful framework for implementing high-performance neural networks with benefits like JIT compilation, automatic differentiation, and excellent hardware acceleration support. Our goal is to create clean, well-documented implementations of open-source LLM architectures that can serve as reference material and starting points for further research.</description><content>&lt;hr>
&lt;p>Before diving into the implementation details,
I want to summarize our approach:
we&amp;rsquo;ll be creating JAX/Flax implementations of popular open-source LLM architectures, documenting everything thoroughly, and providing clear notebooks to demonstrate their usage.&lt;/p>
&lt;h2 id="project-overview">Project Overview&lt;/h2>
&lt;p>JAX, combined with Flax, provides a powerful framework for implementing high-performance neural networks with benefits like JIT compilation, automatic differentiation, and excellent hardware acceleration support. Our goal is to create clean, well-documented implementations of open-source LLM architectures that can serve as reference material and starting points for further research.&lt;/p>
&lt;h2 id="implementation-roadmap">Implementation Roadmap&lt;/h2>
&lt;h3 id="phase-1-environment-setup-and-core-components">Phase 1: Environment Setup and Core Components&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>Development Environment Setup&lt;/strong>
&lt;ul>
&lt;li>Install JAX with hardware-specific optimizations (GPU/TPU)&lt;/li>
&lt;li>Install Flax, Optax (optimizers), and supporting libraries&lt;/li>
&lt;li>Configure development environment with appropriate compute resources&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Implement Core Architecture Components&lt;/strong>
&lt;ul>
&lt;li>Token embedding layers&lt;/li>
&lt;li>Various positional encoding mechanisms (sinusoidal, learned, rotary)&lt;/li>
&lt;li>Attention mechanisms (multi-head attention with causal masking)&lt;/li>
&lt;li>Feed-forward networks&lt;/li>
&lt;li>Normalization layers (LayerNorm, RMSNorm)&lt;/li>
&lt;li>Complete transformer blocks&lt;/li>
&lt;li>Model definition classes with initialization and forward functions&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="phase-2-model-implementations">Phase 2: Model Implementations&lt;/h3>
&lt;p>We&amp;rsquo;ll implement several open-source LLM architectures, starting with simpler models and progressing to more complex ones:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>GPT-2 Style Model&lt;/strong>
&lt;ul>
&lt;li>Decoder-only transformer architecture&lt;/li>
&lt;li>LayerNorm and learned positional embeddings&lt;/li>
&lt;li>Support for various model sizes (124M to 1.5B parameters)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Gemma Architecture&lt;/strong>
&lt;ul>
&lt;li>Google&amp;rsquo;s efficient model developed specifically with JAX/Flax&lt;/li>
&lt;li>RMSNorm and rotary positional embeddings&lt;/li>
&lt;li>2B and 7B parameter configurations&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Additional Models (Time Permitting)&lt;/strong>
&lt;ul>
&lt;li>OpenLLaMA (open-source implementation of LLaMA)&lt;/li>
&lt;li>Mistral (with mixture-of-experts layers)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>For each model, we&amp;rsquo;ll implement:&lt;/p>
&lt;ul>
&lt;li>Complete model definition classes&lt;/li>
&lt;li>Initialization from scratch and from pre-trained weights&lt;/li>
&lt;li>Forward pass functions optimized with JAX transformations&lt;/li>
&lt;li>Text generation utilities&lt;/li>
&lt;/ul>
&lt;h3 id="phase-3-utility-functions-and-optimization">Phase 3: Utility Functions and Optimization&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>Weight Loading Utilities&lt;/strong>
&lt;ul>
&lt;li>Parameter key remapping between different naming schemes&lt;/li>
&lt;li>Shape and data type conversion utilities&lt;/li>
&lt;li>Loading from HuggingFace model repositories&lt;/li>
&lt;li>Checkpoint saving/loading with Orbax&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Inference and Generation&lt;/strong>
&lt;ul>
&lt;li>Greedy decoding implementation&lt;/li>
&lt;li>Sampling-based generation with temperature control&lt;/li>
&lt;li>Top-k and top-p (nucleus) sampling&lt;/li>
&lt;li>Batched inference support&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Performance Optimization&lt;/strong>
&lt;ul>
&lt;li>JIT compilation for faster inference&lt;/li>
&lt;li>Vectorization with vmap for batched processing&lt;/li>
&lt;li>Device parallelism with pmap for multi-GPU/TPU setups&lt;/li>
&lt;li>Memory optimization techniques like gradient checkpointing&lt;/li>
&lt;li>Mixed precision support (bfloat16/fp16)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="phase-4-validation-and-documentation">Phase 4: Validation and Documentation&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>Validation Against Reference Implementations&lt;/strong>
&lt;ul>
&lt;li>Compare outputs with HuggingFace reference models&lt;/li>
&lt;li>Validate hidden states and logits using similarity metrics&lt;/li>
&lt;li>Verify tokenizer consistency&lt;/li>
&lt;li>Test text generation capabilities&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Documentation and Notebooks&lt;/strong>
&lt;ul>
&lt;li>Comprehensive model documentation&lt;/li>
&lt;li>Jupyter notebooks demonstrating usage&lt;/li>
&lt;li>Performance benchmarks&lt;/li>
&lt;li>Best practices for working with JAX/Flax models&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="technical-challenges-and-solutions">Technical Challenges and Solutions&lt;/h2>
&lt;h3 id="api-compatibility">API Compatibility&lt;/h3>
&lt;p>Flax is transitioning from the Linen API to the newer NNX API. We&amp;rsquo;ll need to handle compatibility by:&lt;/p>
&lt;ol>
&lt;li>Using the flax.nnx.bridge API to convert between Linen and NNX modules&lt;/li>
&lt;li>Properly handling RNG keys and variable collections&lt;/li>
&lt;li>Testing thoroughly to ensure compatibility with different versions&lt;/li>
&lt;/ol>
&lt;h3 id="memory-management-for-large-models">Memory Management for Large Models&lt;/h3>
&lt;p>For larger models, we&amp;rsquo;ll implement:&lt;/p>
&lt;ol>
&lt;li>Gradient checkpointing to reduce memory usage during training&lt;/li>
&lt;li>Model parallelism strategies using JAX&amp;rsquo;s device mesh and partition specs&lt;/li>
&lt;li>Efficient parameter handling to minimize memory overhead&lt;/li>
&lt;/ol>
&lt;h3 id="performance-optimization">Performance Optimization&lt;/h3>
&lt;p>To achieve optimal performance, we&amp;rsquo;ll:&lt;/p>
&lt;ol>
&lt;li>Use JAX&amp;rsquo;s transformation functions (jit, vmap, pmap) appropriately&lt;/li>
&lt;li>Apply XLA optimizations through JAX&lt;/li>
&lt;li>Implement custom kernels where necessary using jax.lax operations&lt;/li>
&lt;li>Leverage scan for sequential operations&lt;/li>
&lt;/ol>
&lt;h2 id="repository-structure">Repository Structure&lt;/h2>
&lt;pre tabindex="0">&lt;code>jax-flax-llms/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ components.py (shared transformer components)
â”‚ â”œâ”€â”€ gpt2/
â”‚ â”‚ â”œâ”€â”€ model.py (model definition)
â”‚ â”‚ â”œâ”€â”€ config.py (model configuration)
â”‚ â”‚ â””â”€â”€ utils.py (model-specific utilities)
â”‚ â”œâ”€â”€ gemma/
â”‚ â”‚ â”œâ”€â”€ model.py
â”‚ â”‚ â”œâ”€â”€ config.py
â”‚ â”‚ â””â”€â”€ utils.py
â”‚ â””â”€â”€ ...
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ loading.py (weight loading utilities)
â”‚ â”œâ”€â”€ generation.py (text generation functions)
â”‚ â”œâ”€â”€ optimization.py (performance optimization)
â”‚ â””â”€â”€ validation.py (validation against references)
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_gpt2_tutorial.ipynb
â”‚ â”œâ”€â”€ 02_gemma_tutorial.ipynb
â”‚ â””â”€â”€ ...
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_components.py
â”‚ â”œâ”€â”€ test_gpt2.py
â”‚ â”œâ”€â”€ test_gemma.py
â”‚ â””â”€â”€ ...
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
&lt;/code>&lt;/pre>&lt;h2 id="implementation-approach-for-each-model">Implementation Approach for Each Model&lt;/h2>
&lt;p>For each model (using GPT-2 as an example):&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Architecture Research&lt;/strong>
&lt;ul>
&lt;li>Study the original architecture in detail&lt;/li>
&lt;li>Identify key components and parameter configurations&lt;/li>
&lt;li>Understand tokenization and preprocessing requirements&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Core Implementation&lt;/strong>
&lt;ul>
&lt;li>Define the model class structure&lt;/li>
&lt;li>Implement all necessary layers and components&lt;/li>
&lt;li>Create forward pass function with JAX optimizations&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Weight Loading&lt;/strong>
&lt;ul>
&lt;li>Create mapping between original weights and our implementation&lt;/li>
&lt;li>Implement conversion functions for loading pre-trained weights&lt;/li>
&lt;li>Test with published checkpoints&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Inference and Generation&lt;/strong>
&lt;ul>
&lt;li>Implement text generation capabilities&lt;/li>
&lt;li>Optimize for inference speed using JAX transformations&lt;/li>
&lt;li>Support various decoding strategies&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Documentation and Examples&lt;/strong>
&lt;ul>
&lt;li>Create comprehensive model documentation&lt;/li>
&lt;li>Develop clear notebooks showing initialization, loading, and generation&lt;/li>
&lt;li>Include performance benchmarks&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="tools-and-dependencies">Tools and Dependencies&lt;/h2>
&lt;ol>
&lt;li>&lt;strong>Core Libraries&lt;/strong>
&lt;ul>
&lt;li>JAX and JAXLIB (with GPU/TPU support)&lt;/li>
&lt;li>Flax (neural network library)&lt;/li>
&lt;li>Optax (optimizers)&lt;/li>
&lt;li>Orbax (checkpointing)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Support Libraries&lt;/strong>
&lt;ul>
&lt;li>Transformers (for reference models and tokenizers)&lt;/li>
&lt;li>NumPy and SciPy (numerical computing)&lt;/li>
&lt;li>Matplotlib (visualization)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Development Tools&lt;/strong>
&lt;ul>
&lt;li>Jupyter notebooks (for examples and demonstrations)&lt;/li>
&lt;li>PyTest (for testing)&lt;/li>
&lt;li>GitHub (for version control and publication)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="educational-focus">Educational Focus&lt;/h2>
&lt;p>Since this project is primarily educational, we&amp;rsquo;ll emphasize:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Clear, Well-Documented Code&lt;/strong>
&lt;ul>
&lt;li>Comprehensive docstrings&lt;/li>
&lt;li>Explanatory comments for complex sections&lt;/li>
&lt;li>Consistent style and naming conventions&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Conceptual Understanding&lt;/strong>
&lt;ul>
&lt;li>Explain architecture decisions in documentation&lt;/li>
&lt;li>Compare implementation choices with original models&lt;/li>
&lt;li>Highlight JAX/Flax-specific optimizations&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Practical Examples&lt;/strong>
&lt;ul>
&lt;li>Step-by-step notebooks for different use cases&lt;/li>
&lt;li>Performance comparison between optimization strategies&lt;/li>
&lt;li>Tips and best practices for working with JAX/Flax&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>This project will create a valuable educational resource for researchers and developers interested in implementing LLMs with JAX and Flax. By providing clear, optimized implementations of popular open-source architectures, along with comprehensive documentation and examples, we&amp;rsquo;ll help bridge the gap between theoretical understanding and practical implementation.&lt;/p>
&lt;p>The end result will be a GitHub repository showcasing these implementations, ready for others to use as reference material or starting points for their own research and experimentation.&lt;/p>
&lt;!-- raw HTML omitted --></content></item><item><title>Fine-Tuning Models</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/fine-tuning-models-in-google-colab_-a-practical-gu/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/fine-tuning-models-in-google-colab_-a-practical-gu/</guid><description>Google Collab provides free GPU/TPU resources perfect for fine-tuning AI models. Here&amp;rsquo;s a complete guide to fine-tuning models in Colab, from setup to saving your trained model.
Setting Up Your Colab Environment # 1. Connect to a GPU runtime # Go to Runtime &amp;gt; Change runtime type &amp;gt; GPU # 2. Verify GPU is available !nvidia-smi # 3. Install necessary libraries !pip install -q transformers datasets accelerate peft bitsandbytes trl tensorboard Method 1: QLoRA Fine-Tuning for Large Models This approach is ideal for 7B+ parameter models on Colab&amp;rsquo;s limited GPU:</description><content>&lt;p>Google Collab provides free GPU/TPU resources perfect for fine-tuning AI models. Here&amp;rsquo;s a complete guide to fine-tuning models in Colab, from setup to saving your trained model.&lt;/p>
&lt;h2 id="setting-up-your-colab-environment">Setting Up Your Colab Environment&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># 1. Connect to a GPU runtime&lt;/span>
&lt;span style="color:#75715e"># Go to Runtime &amp;gt; Change runtime type &amp;gt; GPU&lt;/span>
&lt;span style="color:#75715e"># 2. Verify GPU is available&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">!&lt;/span>nvidia&lt;span style="color:#f92672">-&lt;/span>smi
&lt;span style="color:#75715e"># 3. Install necessary libraries&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">!&lt;/span>pip install &lt;span style="color:#f92672">-&lt;/span>q transformers datasets accelerate peft bitsandbytes trl tensorboard
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="method-1-qlora-fine-tuning-for-large-models">Method 1: QLoRA Fine-Tuning for Large Models&lt;/h2>
&lt;p>This approach is ideal for 7B+ parameter models on Colab&amp;rsquo;s limited GPU:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># Import libraries&lt;/span>
&lt;span style="color:#f92672">import&lt;/span> torch
&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
&lt;span style="color:#f92672">from&lt;/span> peft &lt;span style="color:#f92672">import&lt;/span> LoraConfig, get_peft_model
&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> load_dataset
&lt;span style="color:#f92672">from&lt;/span> trl &lt;span style="color:#f92672">import&lt;/span> SFTTrainer, SFTConfig
&lt;span style="color:#75715e"># Configure quantization&lt;/span>
bnb_config &lt;span style="color:#f92672">=&lt;/span> BitsAndBytesConfig(
load_in_4bit&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,
bnb_4bit_quant_type&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;nf4&amp;#34;&lt;/span>,
bnb_4bit_compute_dtype&lt;span style="color:#f92672">=&lt;/span>torch&lt;span style="color:#f92672">.&lt;/span>float16
)
&lt;span style="color:#75715e"># Load model and tokenizer&lt;/span>
model_id &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;meta-llama/Llama-2-7b-hf&amp;#34;&lt;/span> &lt;span style="color:#75715e"># Or any compatible model&lt;/span>
tokenizer &lt;span style="color:#f92672">=&lt;/span> AutoTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(model_id)
tokenizer&lt;span style="color:#f92672">.&lt;/span>pad_token &lt;span style="color:#f92672">=&lt;/span> tokenizer&lt;span style="color:#f92672">.&lt;/span>eos_token
model &lt;span style="color:#f92672">=&lt;/span> AutoModelForCausalLM&lt;span style="color:#f92672">.&lt;/span>from_pretrained(
model_id,
quantization_config&lt;span style="color:#f92672">=&lt;/span>bnb_config,
device_map&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;auto&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e"># Configure LoRA&lt;/span>
lora_config &lt;span style="color:#f92672">=&lt;/span> LoraConfig(
r&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">16&lt;/span>,
lora_alpha&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">32&lt;/span>,
lora_dropout&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.05&lt;/span>,
bias&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;none&amp;#34;&lt;/span>,
task_type&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;CAUSAL_LM&amp;#34;&lt;/span>,
target_modules&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;q_proj&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;v_proj&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;k_proj&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_proj&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;gate_proj&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;up_proj&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;down_proj&amp;#34;&lt;/span>]
)
&lt;span style="color:#75715e"># Apply LoRA to model&lt;/span>
model &lt;span style="color:#f92672">=&lt;/span> get_peft_model(model, lora_config)
model&lt;span style="color:#f92672">.&lt;/span>print_trainable_parameters()
&lt;span style="color:#75715e"># Prepare dataset&lt;/span>
&lt;span style="color:#75715e"># Option 1: Load from Hugging Face&lt;/span>
dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(&lt;span style="color:#e6db74">&amp;#34;Abirate/english_quotes&amp;#34;&lt;/span>, split&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>)
&lt;span style="color:#75715e"># Option 2: Or upload CSV to Colab&lt;/span>
&lt;span style="color:#f92672">from&lt;/span> google.colab &lt;span style="color:#f92672">import&lt;/span> files
uploaded &lt;span style="color:#f92672">=&lt;/span> files&lt;span style="color:#f92672">.&lt;/span>upload() &lt;span style="color:#75715e"># Upload your CSV&lt;/span>
&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> Dataset
df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;your_file.csv&amp;#34;&lt;/span>)
dataset &lt;span style="color:#f92672">=&lt;/span> Dataset&lt;span style="color:#f92672">.&lt;/span>from_pandas(df)
&lt;span style="color:#75715e"># Configure trainer&lt;/span>
training_args &lt;span style="color:#f92672">=&lt;/span> SFTConfig(
output_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;./results&amp;#34;&lt;/span>,
num_train_epochs&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>,
per_device_train_batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4&lt;/span>,
gradient_accumulation_steps&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4&lt;/span>,
learning_rate&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2e-4&lt;/span>,
logging_steps&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">50&lt;/span>,
save_strategy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;epoch&amp;#34;&lt;/span>,
fp16&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,
)
&lt;span style="color:#75715e"># Initialize trainer&lt;/span>
trainer &lt;span style="color:#f92672">=&lt;/span> SFTTrainer(
model&lt;span style="color:#f92672">=&lt;/span>model,
args&lt;span style="color:#f92672">=&lt;/span>training_args,
train_dataset&lt;span style="color:#f92672">=&lt;/span>dataset,
tokenizer&lt;span style="color:#f92672">=&lt;/span>tokenizer,
dataset_text_field&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;quote&amp;#34;&lt;/span> &lt;span style="color:#75715e"># Change to your text column name&lt;/span>
)
&lt;span style="color:#75715e"># Start training&lt;/span>
trainer&lt;span style="color:#f92672">.&lt;/span>train()
&lt;span style="color:#75715e"># Save the model&lt;/span>
peft_model_id &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;my-fine-tuned-model&amp;#34;&lt;/span>
trainer&lt;span style="color:#f92672">.&lt;/span>model&lt;span style="color:#f92672">.&lt;/span>save_pretrained(peft_model_id)
tokenizer&lt;span style="color:#f92672">.&lt;/span>save_pretrained(peft_model_id)
&lt;span style="color:#75715e"># Save to Google Drive (to avoid losing work)&lt;/span>
&lt;span style="color:#f92672">from&lt;/span> google.colab &lt;span style="color:#f92672">import&lt;/span> drive
drive&lt;span style="color:#f92672">.&lt;/span>mount(&lt;span style="color:#e6db74">&amp;#39;/content/drive&amp;#39;&lt;/span>)
&lt;span style="color:#960050;background-color:#1e0010">!&lt;/span>cp &lt;span style="color:#f92672">-&lt;/span>r {peft_model_id} &lt;span style="color:#f92672">/&lt;/span>content&lt;span style="color:#f92672">/&lt;/span>drive&lt;span style="color:#f92672">/&lt;/span>MyDrive&lt;span style="color:#f92672">/&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="method-2-full-fine-tuning-for-smaller-models">Method 2: Full Fine-Tuning for Smaller Models&lt;/h2>
&lt;p>For smaller models (under 3B parameters) that fit fully in Colab&amp;rsquo;s GPU:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#f92672">import&lt;/span> torch
&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer
&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> load_dataset
&lt;span style="color:#75715e"># Load model and tokenizer&lt;/span>
model_id &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;gpt2&amp;#34;&lt;/span> &lt;span style="color:#75715e"># Or another smaller model&lt;/span>
tokenizer &lt;span style="color:#f92672">=&lt;/span> AutoTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(model_id)
tokenizer&lt;span style="color:#f92672">.&lt;/span>pad_token &lt;span style="color:#f92672">=&lt;/span> tokenizer&lt;span style="color:#f92672">.&lt;/span>eos_token
model &lt;span style="color:#f92672">=&lt;/span> AutoModelForCausalLM&lt;span style="color:#f92672">.&lt;/span>from_pretrained(model_id)
&lt;span style="color:#75715e"># Prepare your dataset&lt;/span>
dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(&lt;span style="color:#e6db74">&amp;#34;imdb&amp;#34;&lt;/span>, split&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>)
&lt;span style="color:#75715e"># Define data preprocessing&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">tokenize_function&lt;/span>(examples):
&lt;span style="color:#66d9ef">return&lt;/span> tokenizer(examples[&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>], padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;max_length&amp;#34;&lt;/span>, truncation&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>, max_length&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">512&lt;/span>)
tokenized_datasets &lt;span style="color:#f92672">=&lt;/span> dataset&lt;span style="color:#f92672">.&lt;/span>map(tokenize_function, batched&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;span style="color:#75715e"># Configure training&lt;/span>
training_args &lt;span style="color:#f92672">=&lt;/span> TrainingArguments(
output_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;./results&amp;#34;&lt;/span>,
num_train_epochs&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>,
per_device_train_batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span>,
save_strategy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;epoch&amp;#34;&lt;/span>,
evaluation_strategy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;epoch&amp;#34;&lt;/span>,
logging_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;./logs&amp;#34;&lt;/span>,
)
&lt;span style="color:#75715e"># Initialize trainer&lt;/span>
trainer &lt;span style="color:#f92672">=&lt;/span> Trainer(
model&lt;span style="color:#f92672">=&lt;/span>model,
args&lt;span style="color:#f92672">=&lt;/span>training_args,
train_dataset&lt;span style="color:#f92672">=&lt;/span>tokenized_datasets,
)
&lt;span style="color:#75715e"># Start training&lt;/span>
trainer&lt;span style="color:#f92672">.&lt;/span>train()
&lt;span style="color:#75715e"># Save the model&lt;/span>
model&lt;span style="color:#f92672">.&lt;/span>save_pretrained(&lt;span style="color:#e6db74">&amp;#34;./fine-tuned-gpt2&amp;#34;&lt;/span>)
tokenizer&lt;span style="color:#f92672">.&lt;/span>save_pretrained(&lt;span style="color:#e6db74">&amp;#34;./fine-tuned-gpt2&amp;#34;&lt;/span>)
&lt;span style="color:#75715e"># Save to Google Drive&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">!&lt;/span>cp &lt;span style="color:#f92672">-&lt;/span>r &lt;span style="color:#f92672">./&lt;/span>fine&lt;span style="color:#f92672">-&lt;/span>tuned&lt;span style="color:#f92672">-&lt;/span>gpt2 &lt;span style="color:#f92672">/&lt;/span>content&lt;span style="color:#f92672">/&lt;/span>drive&lt;span style="color:#f92672">/&lt;/span>MyDrive&lt;span style="color:#f92672">/&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="dealing-with-colab-limitations">Dealing with Colab Limitations&lt;/h2>
&lt;h3 id="session-timeouts">Session Timeouts&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># Add this to prevent idle timeouts&lt;/span>
&lt;span style="color:#f92672">from&lt;/span> IPython.display &lt;span style="color:#f92672">import&lt;/span> display, Javascript
display(Javascript(&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span style="color:#e6db74">function ClickConnect(){
&lt;/span>&lt;span style="color:#e6db74"> console.log(&amp;#34;Clicking connect button&amp;#34;);
&lt;/span>&lt;span style="color:#e6db74"> document.querySelector(&amp;#34;colab-connect-button&amp;#34;).click()
&lt;/span>&lt;span style="color:#e6db74">}
&lt;/span>&lt;span style="color:#e6db74">setInterval(ClickConnect, 60000)
&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;&lt;/span>))
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="memory-management">Memory Management&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># Clear GPU memory if needed&lt;/span>
&lt;span style="color:#f92672">import&lt;/span> gc
gc&lt;span style="color:#f92672">.&lt;/span>collect()
torch&lt;span style="color:#f92672">.&lt;/span>cuda&lt;span style="color:#f92672">.&lt;/span>empty_cache()
&lt;span style="color:#75715e"># Monitor memory usage&lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">!&lt;/span>nvidia&lt;span style="color:#f92672">-&lt;/span>smi
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="checkpointing">Checkpointing&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># Configure checkpointing for recovery&lt;/span>
training_args &lt;span style="color:#f92672">=&lt;/span> TrainingArguments(
&lt;span style="color:#75715e"># ... other args&lt;/span>
save_strategy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;steps&amp;#34;&lt;/span>,
save_steps&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">500&lt;/span>,
save_total_limit&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#75715e"># Keep only the last 2 checkpoints&lt;/span>
)
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="testing-your-fine-tuned-model">Testing Your Fine-Tuned Model&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#75715e"># Load your fine-tuned model&lt;/span>
&lt;span style="color:#f92672">from&lt;/span> peft &lt;span style="color:#f92672">import&lt;/span> PeftModel, PeftConfig
&lt;span style="color:#75715e"># For LoRA models&lt;/span>
config &lt;span style="color:#f92672">=&lt;/span> PeftConfig&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;my-fine-tuned-model&amp;#34;&lt;/span>)
model &lt;span style="color:#f92672">=&lt;/span> AutoModelForCausalLM&lt;span style="color:#f92672">.&lt;/span>from_pretrained(
config&lt;span style="color:#f92672">.&lt;/span>base_model_name_or_path,
torch_dtype&lt;span style="color:#f92672">=&lt;/span>torch&lt;span style="color:#f92672">.&lt;/span>float16,
device_map&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;auto&amp;#34;&lt;/span>
)
model &lt;span style="color:#f92672">=&lt;/span> PeftModel&lt;span style="color:#f92672">.&lt;/span>from_pretrained(model, &lt;span style="color:#e6db74">&amp;#34;my-fine-tuned-model&amp;#34;&lt;/span>)
&lt;span style="color:#75715e"># Generate text&lt;/span>
tokenizer &lt;span style="color:#f92672">=&lt;/span> AutoTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;my-fine-tuned-model&amp;#34;&lt;/span>)
inputs &lt;span style="color:#f92672">=&lt;/span> tokenizer(&lt;span style="color:#e6db74">&amp;#34;Your prompt text here&amp;#34;&lt;/span>, return_tensors&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;pt&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>to(&lt;span style="color:#e6db74">&amp;#34;cuda&amp;#34;&lt;/span>)
outputs &lt;span style="color:#f92672">=&lt;/span> model&lt;span style="color:#f92672">.&lt;/span>generate(&lt;span style="color:#f92672">**&lt;/span>inputs, max_length&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>)
print(tokenizer&lt;span style="color:#f92672">.&lt;/span>decode(outputs[&lt;span style="color:#ae81ff">0&lt;/span>], skip_special_tokens&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>))
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="best-practices-for-colab-fine-tuning">Best Practices for Colab Fine-Tuning&lt;/h2>
&lt;ol>
&lt;li>&lt;strong>Always connect to Google Drive&lt;/strong> to prevent losing work if Collab disconnects&lt;/li>
&lt;li>&lt;strong>Start small&lt;/strong> - Test your pipeline with a tiny subset of data before full training&lt;/li>
&lt;li>&lt;strong>Monitor GPU usage&lt;/strong> regularly with &lt;code>!nvidia-smi&lt;/code>&lt;/li>
&lt;li>&lt;strong>Use QLoRA for large models&lt;/strong> - It&amp;rsquo;s the most efficient way to fine-tune on Colab&lt;/li>
&lt;li>&lt;strong>Save checkpoints frequently&lt;/strong> and to Google Drive&lt;/li>
&lt;li>&lt;strong>Close other tabs&lt;/strong> in your browser to prevent Collab from disconnecting due to inactivity&lt;/li>
&lt;/ol>
&lt;p>This guide provides everything you need to fine-tune models in Google Collab, from small BERT variants all the way to 7B+ parameter models using memory-efficient techniques.&lt;/p></content></item><item><title>Obsidian Notes -> Blogs</title><link>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/my-blogging-setup/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://whitewolf2000ani.github.io/AnikiBlogs/posts/blogs/my-blogging-setup/</guid><description>Why am I doing this? A Repository or a store for whatever cool concepts I study/Understand. It&amp;rsquo;s really important to learn in Public. How am I doing this? Obsidian https://obsidian.md/ Hugo for building the static website blazingly fast. Why are we using HUGO? The simple answer is HUGO converts Markdown files to Website code directly(Isn&amp;rsquo;t this convenientðŸ˜)
Prerequisites for Hugo Git -&amp;gt; Install According to Operating System.</description><content>&lt;h2 id="why-am-i-doing-this">Why am I doing this?&lt;/h2>
&lt;ul>
&lt;li>A Repository or a store for whatever cool concepts I study/Understand.&lt;/li>
&lt;li>It&amp;rsquo;s really important to learn in Public.&lt;/li>
&lt;/ul>
&lt;h2 id="how-am-i-doing-this">How am I doing this?&lt;/h2>
&lt;ul>
&lt;li>Obsidian &lt;a href="https://obsidian.md/">https://obsidian.md/&lt;/a>&lt;/li>
&lt;li>&lt;img src="https://whitewolf2000ani.github.io/AnikiBlogs/images/Pasted_image_20241203121609.png" alt="Image Description">&lt;/li>
&lt;li>Hugo for building the static website blazingly fast.&lt;/li>
&lt;/ul>
&lt;h2 id="why-are-we-using-hugo">Why are we using HUGO?&lt;/h2>
&lt;p>The simple answer is HUGO converts Markdown files to Website code directly(Isn&amp;rsquo;t this convenientðŸ˜)&lt;/p>
&lt;ul>
&lt;li>Prerequisites for Hugo
&lt;ul>
&lt;li>Git -&amp;gt; Install According to Operating System.
&lt;ul>
&lt;li>Prompt: How do Install Git in &amp;ldquo;Operating System&amp;rdquo;.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Go -&amp;gt; Install According to Operating System.
&lt;ul>
&lt;li>Prompt: How to Install Go in &amp;ldquo;Operating system&amp;rdquo;.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Install HUGO following the official documentation &lt;a href="https://gohugo.io/installation/linux/">https://gohugo.io/installation/linux/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="the-next-steps">The next Steps&lt;/h2>
&lt;ul>
&lt;li>Create a Folder for your blogs.&lt;/li>
&lt;li>Move into that folder and use command&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">hugo new site &amp;lt;NameOfSite&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>The required files for HUGO will be created.&lt;/li>
&lt;li>Initialize a Git repository&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">git init
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Choose a exciting theme of choice. -&amp;gt; &lt;a href="https://themes.gohugo.io/">https://themes.gohugo.io/&lt;/a>
&lt;ul>
&lt;li>After choosing a theme, -&amp;gt; &lt;a href="https://themes.gohugo.io/themes/hugo-theme-terminal/">https://themes.gohugo.io/themes/hugo-theme-terminal/&lt;/a>&lt;/li>
&lt;li>Find &amp;ldquo;Install theme as submodule&amp;rdquo; this is the easiest and best way to use the Theme.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">//similar to this command
git submodule add -f https://github.com/panr/hugo-theme-terminal.git themes/terminal
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>We need to configure the &amp;ldquo;config.toml&amp;rdquo; file in order to render the theme (e.g. Config file for terminal theme)&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-config.toml" data-lang="config.toml">
&lt;span style="color:#960050;background-color:#1e0010">//&lt;/span> &lt;span style="color:#a6e22e">Example&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span> &lt;span style="color:#a6e22e">for&lt;/span> &lt;span style="color:#a6e22e">terminal&lt;/span> &lt;span style="color:#a6e22e">theme&lt;/span>
&lt;span style="color:#a6e22e">baseurl&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">languageCode&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;en-us&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Add it only if you keep the theme in the `themes` directory. &lt;/span>
&lt;span style="color:#75715e"># Remove it if you use the theme as a remote Hugo Module. &lt;/span>
&lt;span style="color:#a6e22e">theme&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;terminal&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">paginate&lt;/span> = &lt;span style="color:#ae81ff">5&lt;/span>
[&lt;span style="color:#a6e22e">params&lt;/span>]
&lt;span style="color:#75715e"># dir name of your main content (default is `content/posts`). &lt;/span>
&lt;span style="color:#75715e"># the list of set content will show up on your index page (baseurl). &lt;/span>
&lt;span style="color:#a6e22e">contentTypeName&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;posts&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># if you set this to 0, only submenu trigger will be visible &lt;/span>
&lt;span style="color:#a6e22e">showMenuItems&lt;/span> = &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># show selector to switch language &lt;/span>
&lt;span style="color:#a6e22e">showLanguageSelector&lt;/span> = &lt;span style="color:#66d9ef">false&lt;/span>
&lt;span style="color:#75715e"># set theme to full screen width &lt;/span>
&lt;span style="color:#a6e22e">fullWidthTheme&lt;/span> = &lt;span style="color:#66d9ef">false&lt;/span>
&lt;span style="color:#75715e"># center theme with default width &lt;/span>
&lt;span style="color:#a6e22e">centerTheme&lt;/span> = &lt;span style="color:#66d9ef">false&lt;/span>
&lt;span style="color:#75715e"># if your resource directory contains an image called `cover.(jpg|png|webp)`, &lt;/span>
&lt;span style="color:#75715e"># then the file will be used as a cover automatically. &lt;/span>
&lt;span style="color:#75715e"># With this option you don&amp;#39;t have to put the `cover` param in a front-matter. &lt;/span>
&lt;span style="color:#a6e22e">autoCover&lt;/span> = &lt;span style="color:#66d9ef">true&lt;/span>
&lt;span style="color:#75715e"># set post to show the last updated # If you use git, you can set `enableGitInfo` to `true` and then post will automatically get the last updated &lt;/span>
&lt;span style="color:#a6e22e">showLastUpdated&lt;/span> = &lt;span style="color:#66d9ef">false&lt;/span>
&lt;span style="color:#75715e"># Provide a string as a prefix for the last update date. By default, it looks like this: 2020-xx-xx [Updated: 2020-xx-xx] :: Author &lt;/span>
&lt;span style="color:#75715e"># updatedDatePrefix = &amp;#34;Updated&amp;#34; # whether to show a page&amp;#39;s estimated reading time # readingTime = false # default &lt;/span>
&lt;span style="color:#75715e"># whether to show a table of contents &lt;/span>
&lt;span style="color:#75715e"># can be overridden in a page&amp;#39;s front-matter &lt;/span>
&lt;span style="color:#75715e"># Toc = false # default &lt;/span>
&lt;span style="color:#75715e"># set title for the table of contents &lt;/span>
&lt;span style="color:#75715e"># can be overridden in a page&amp;#39;s front-matter &lt;/span>
&lt;span style="color:#75715e"># TocTitle = &amp;#34;Table of Contents&amp;#34; &lt;/span>
&lt;span style="color:#75715e"># default [params.twitter] &lt;/span>
&lt;span style="color:#75715e"># set Twitter handles for Twitter cards &lt;/span>
&lt;span style="color:#75715e"># see https://developer.twitter.com/en/docs/tweets/optimize-with-cards/guides/getting-started#card-and-content-attribution &lt;/span>
&lt;span style="color:#75715e"># do not include &lt;/span>
&lt;span style="color:#960050;background-color:#1e0010">@&lt;/span> &lt;span style="color:#a6e22e">creator&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">site&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
[&lt;span style="color:#a6e22e">languages&lt;/span>]
[&lt;span style="color:#a6e22e">languages&lt;/span>.&lt;span style="color:#a6e22e">en&lt;/span>]
&lt;span style="color:#a6e22e">languageName&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;English&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">title&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Terminal&amp;#34;&lt;/span>
[&lt;span style="color:#a6e22e">languages&lt;/span>.&lt;span style="color:#a6e22e">en&lt;/span>.&lt;span style="color:#a6e22e">params&lt;/span>]
&lt;span style="color:#a6e22e">subtitle&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;A simple, retro theme for Hugo&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">owner&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">keywords&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">copyright&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">menuMore&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Show more&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">readMore&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Read more&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">readOtherPosts&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Read other posts&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">newerPosts&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Newer posts&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">olderPosts&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Older posts&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">missingContentMessage&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Page not found...&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">missingBackButtonLabel&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Back to home page&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">minuteReadingTime&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;min read&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">words&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;words&amp;#34;&lt;/span>
[&lt;span style="color:#a6e22e">languages&lt;/span>.&lt;span style="color:#a6e22e">en&lt;/span>.&lt;span style="color:#a6e22e">params&lt;/span>.&lt;span style="color:#a6e22e">logo&lt;/span>]
&lt;span style="color:#a6e22e">logoText&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Terminal&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">logoHomeLink&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/&amp;#34;&lt;/span>
[&lt;span style="color:#a6e22e">languages&lt;/span>.&lt;span style="color:#a6e22e">en&lt;/span>.&lt;span style="color:#a6e22e">menu&lt;/span>]
[[&lt;span style="color:#a6e22e">languages&lt;/span>.&lt;span style="color:#a6e22e">en&lt;/span>.&lt;span style="color:#a6e22e">menu&lt;/span>.&lt;span style="color:#a6e22e">main&lt;/span>]]
&lt;span style="color:#a6e22e">identifier&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;about&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">name&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;About&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">url&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/about&amp;#34;&lt;/span>
[[&lt;span style="color:#a6e22e">languages&lt;/span>.&lt;span style="color:#a6e22e">en&lt;/span>.&lt;span style="color:#a6e22e">menu&lt;/span>.&lt;span style="color:#a6e22e">main&lt;/span>]]
&lt;span style="color:#a6e22e">identifier&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;showcase&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">name&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;Showcase&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">url&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/showcase&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>After this a simple command of&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">hugo server -t &amp;lt;themename&amp;gt;
&lt;/code>&lt;/pre>&lt;h2 id="now-lets-see-some-text-rendering-">Now lets see some text rendering? ðŸ–‹ï¸&lt;/h2>
&lt;ul>
&lt;li>But there seems to be problemðŸ˜, the obsidian blog folder and our hugo blog folder are in different locations.&lt;/li>
&lt;li>The content in them should sync simultaneously.&lt;/li>
&lt;li>We will solve this problem using a very specific command both in linux and Windows.&lt;/li>
&lt;/ul>
&lt;p>linux&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">rsync -av --delete &amp;quot;sourcepath&amp;quot; &amp;quot;destinationpath&amp;quot;
&lt;/code>&lt;/pre>&lt;p>Windows&lt;/p>
&lt;pre tabindex="0">&lt;code>robocopy sourcepath destination path /mir
&lt;/code>&lt;/pre>&lt;h2 id="now-lets-render-the-images">Now lets render the images&lt;/h2>
&lt;ul>
&lt;li>One more problem that we see here is the rendering of images.&lt;/li>
&lt;li>The problem arises because obsidian keeps a different attachments folder for media.&lt;/li>
&lt;li>Now we need to copy the images used in our blog to the Hugo codebase.&lt;/li>
&lt;li>So we will use a python script to copy all the used images from the attachments folder to folder inside static/images/&lt;/li>
&lt;li>Use this python script naming it as images.py and run it to see the magicðŸ˜.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-Python" data-lang="Python">&lt;span style="color:#f92672">import&lt;/span> os
&lt;span style="color:#f92672">import&lt;/span> re
&lt;span style="color:#f92672">import&lt;/span> shutil
&lt;span style="color:#75715e"># Paths&lt;/span>
posts_dir &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;lt;Blog.md Destination inside&amp;gt;&amp;#34;&lt;/span>
attachments_dir &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">r&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;lt;Path where obsidian stores its images&amp;gt;&amp;#34;&lt;/span>
static_images_dir &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;lt;Path of static/images directory where you want to copy your images&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Base URL for Hugo&lt;/span>
baseURL &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;https://whitewolf2000ani.github.io/AnikiBlogs&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Ensure static images directory exists&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>exists(static_images_dir):
Â  Â  os&lt;span style="color:#f92672">.&lt;/span>makedirs(static_images_dir)
&lt;span style="color:#75715e"># Function to normalize image names (replace spaces with underscores)&lt;/span>
&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">normalize_image_name&lt;/span>(image_name):
Â  Â  &lt;span style="color:#66d9ef">return&lt;/span> image_name&lt;span style="color:#f92672">.&lt;/span>replace(&lt;span style="color:#e6db74">&amp;#34; &amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;_&amp;#34;&lt;/span>)
Â  Â 
&lt;span style="color:#75715e"># Process each Markdown file in the posts directory&lt;/span>
&lt;span style="color:#66d9ef">for&lt;/span> filename &lt;span style="color:#f92672">in&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>listdir(posts_dir):
Â  Â  &lt;span style="color:#66d9ef">if&lt;/span> filename&lt;span style="color:#f92672">.&lt;/span>endswith(&lt;span style="color:#e6db74">&amp;#34;.md&amp;#34;&lt;/span>):
Â  Â  Â  Â  filepath &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(posts_dir, filename)
Â  Â  Â  Â  &lt;span style="color:#66d9ef">with&lt;/span> open(filepath, &lt;span style="color:#e6db74">&amp;#34;r&amp;#34;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> file:
Â  Â  Â  Â  Â  Â  content &lt;span style="color:#f92672">=&lt;/span> file&lt;span style="color:#f92672">.&lt;/span>read()
Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  &lt;span style="color:#75715e"># Find all image links in the format `![[filename.extension]]`&lt;/span>
Â  Â  Â  Â  images &lt;span style="color:#f92672">=&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>findall(&lt;span style="color:#e6db74">r&lt;/span>&lt;span style="color:#e6db74">&amp;#34;!\[\[([^]]+\.(?:png|jpg|jpeg|gif|webp))\]\]&amp;#34;&lt;/span>, content)
Â  Â  Â  Â  &lt;span style="color:#66d9ef">for&lt;/span> image &lt;span style="color:#f92672">in&lt;/span> images:
Â  Â  Â  Â  Â  Â  &lt;span style="color:#75715e"># Normalize the image filename&lt;/span>
Â  Â  Â  Â  Â  Â  normalized_image_name &lt;span style="color:#f92672">=&lt;/span> normalize_image_name(image)
Â  Â  Â  Â  Â  Â  &lt;span style="color:#75715e"># Original and normalized filenames&lt;/span>
Â  Â  Â  Â  Â  Â  image_with_spaces &lt;span style="color:#f92672">=&lt;/span> image
Â  Â  Â  Â  Â  Â  image_with_encoded_spaces &lt;span style="color:#f92672">=&lt;/span> normalized_image_name
Â  Â  Â  Â  Â  Â  &lt;span style="color:#75715e"># Path to the original image&lt;/span>
Â  Â  Â  Â  Â  Â  image_source &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(attachments_dir, image_with_spaces)
Â  Â  Â  Â  Â  Â  print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Checking for image: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>image_source&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
Â  Â  Â  Â  Â  Â  &lt;span style="color:#75715e"># Replace Markdown link with a Hugo-compatible link&lt;/span>
Â  Â  Â  Â  Â  Â  new_image_link &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;![Image Description](&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>baseURL&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">/images/&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>image_with_encoded_spaces&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">)&amp;#34;&lt;/span>
Â  Â  Â  Â  Â  Â  content &lt;span style="color:#f92672">=&lt;/span> content&lt;span style="color:#f92672">.&lt;/span>replace(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;![[&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>image_with_spaces&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">]]&amp;#34;&lt;/span>, new_image_link)
Â  Â  Â  Â  Â  Â  &lt;span style="color:#75715e"># Copy the image to the static directory if it exists&lt;/span>
Â  Â  Â  Â  Â  Â  &lt;span style="color:#66d9ef">if&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>exists(image_source):
Â  Â  Â  Â  Â  Â  Â  Â  &lt;span style="color:#75715e"># Copy the image to the static directory with a normalized name&lt;/span>
Â  Â  Â  Â  Â  Â  Â  Â  shutil&lt;span style="color:#f92672">.&lt;/span>copy(image_source, os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(static_images_dir, normalized_image_name))
Â  Â  Â  Â  Â  Â  Â  Â  print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Copied: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>image_source&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> -&amp;gt; &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>static_images_dir&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">/&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>normalized_image_name&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
Â  Â  Â  Â  Â  Â  &lt;span style="color:#66d9ef">else&lt;/span>:
Â  Â  Â  Â  Â  Â  Â  Â  print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Image not found: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>image_source&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
Â  Â  Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  &lt;span style="color:#75715e"># Write updated content back to the file&lt;/span>
Â  Â  Â  Â  &lt;span style="color:#66d9ef">with&lt;/span> open(filepath, &lt;span style="color:#e6db74">&amp;#34;w&amp;#34;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> file:
Â  Â  Â  Â  Â  Â  file&lt;span style="color:#f92672">.&lt;/span>write(content)
print(&lt;span style="color:#e6db74">&amp;#34;Markdown files processed and images copied successfully.&amp;#34;&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>After using the below script run.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-terminal" data-lang="terminal">python3 images.py
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>
&lt;p>This will copy all the images used in the current blog to the images folder inside static.
&lt;img src="https://whitewolf2000ani.github.io/AnikiBlogs/images/Pasted_image_20241203173907.png" alt="Image Description">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>After the images are copied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run the file syncing command.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Start the Hugo server.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Whoosh the image has been rendered on our localhost.
&lt;img src="https://whitewolf2000ani.github.io/AnikiBlogs/images/Pasted_image_20241203181859.png" alt="Image Description">&lt;/p>
&lt;h2 id="do-we-always-have-to-run-the-sync-command-and-then-copy-the-images">Do we always have to run the sync command and then copy the images?&lt;/h2>
&lt;ul>
&lt;li>The simple answer is yes, but we will automate the entire task using a python script at the end of the blog.&lt;/li>
&lt;/ul>
&lt;h2 id="now-lets-put-this-out-in-the-openpun-intended">Now let&amp;rsquo;s put this out in the open(Pun intended)ðŸ˜&lt;/h2>
&lt;ul>
&lt;li>Remember the &amp;ldquo;git init&amp;rdquo; command we used to initialize a git repository, now we will use the local repo.&lt;/li>
&lt;li>Step 1: Go to &lt;a href="http://www.github.com">www.github.com&lt;/a>&lt;/li>
&lt;li>Step 2: Create a new repository.&lt;/li>
&lt;li>step 3: Connect the local repository to your remote repository.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">git remote add origin &amp;lt;/ssh /https link&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>step 4: Run Hugo to create all the necessary changes.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">hugo
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Step 5: Now add all the changes made.&lt;/li>
&lt;li>Step 6: Commit these changes with a valid comment.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">git add.
git commit -m &amp;quot;My, first commit to the blog&amp;quot;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Step 7: Push these changes to GitHub/ remote.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code>git push -u origin master
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Now we will see the changes in our Remote GitHub Repository(or simply on the GitHub Website).&lt;/li>
&lt;/ul>
&lt;h2 id="now-the-moment-of-truth-where-should-we-host-our-website-">Now the moment of Truth, where should we host our website ðŸ¤”?&lt;/h2>
&lt;ul>
&lt;li>Vercel/ GitHub pages/ Hostinger.&lt;/li>
&lt;li>I will be using GitHub pages.
&lt;ul>
&lt;li>It&amp;rsquo;s good for static websites.&lt;/li>
&lt;li>It&amp;rsquo;s free ðŸ˜.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Let&amp;rsquo;s do it.&lt;/li>
&lt;li>Step 1: We are creating a separate branch for deploying the Blog.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">git checkout --orphan gh-pages
git rm -rf .
echo &amp;quot;This is the gh-pages branch&amp;quot; &amp;gt; README.md
git add README.md
git commit -m &amp;quot;Initialize gh-pages branch&amp;quot;
git push origin gh-pages
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Step 2: Configure GitHub pages.
&lt;ul>
&lt;li>Inside your blogs repository there is click on the settings icon.&lt;/li>
&lt;li>Navigate to the Code and Automation Section.&lt;/li>
&lt;li>Click on Actions.&lt;/li>
&lt;li>Click on General.
&lt;img src="https://whitewolf2000ani.github.io/AnikiBlogs/images/Pasted_image_20241204215856.png" alt="Image Description">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Under the Workflow permissions-&amp;gt; click on Read and Write permissions.&lt;/li>
&lt;li>Step 3: Under the Pages section set the source to gh-pages branch and /root directory.&lt;/li>
&lt;li>Step 4: Now checkout to the master branch&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">git checkout master
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Step 5: Create the &lt;code>.github/workflows/deploy.yml&lt;/code> file with the deployment instructions.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-deploy.yml" data-lang="deploy.yml">&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Deploy Hugo to GitHub Pages&lt;/span>
&lt;span style="color:#f92672">on&lt;/span>:
&lt;span style="color:#f92672">push&lt;/span>:
&lt;span style="color:#f92672">branches&lt;/span>:
- &lt;span style="color:#ae81ff">master &lt;/span> &lt;span style="color:#75715e"># Your main branch name&lt;/span>
&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;span style="color:#f92672">deploy&lt;/span>:
&lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;span style="color:#f92672">steps&lt;/span>:
- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Checkout code&lt;/span>
&lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/checkout@v3&lt;/span>
&lt;span style="color:#f92672">with&lt;/span>:
&lt;span style="color:#f92672">submodules&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span> &lt;span style="color:#75715e"># Fetch submodules if any&lt;/span>
- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Install Hugo&lt;/span>
&lt;span style="color:#f92672">run&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74"> wget https://github.com/gohugoio/hugo/releases/download/v0.92.2/hugo_extended_0.92.2_Linux-64bit.tar.gz
&lt;/span>&lt;span style="color:#e6db74"> tar -xzf hugo_extended_0.92.2_Linux-64bit.tar.gz -C /usr/local/bin&lt;/span>
- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Build site&lt;/span>
&lt;span style="color:#f92672">run&lt;/span>: &lt;span style="color:#ae81ff">hugo --minify&lt;/span>
- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Deploy to gh-pages&lt;/span>
&lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">peaceiris/actions-gh-pages@v3&lt;/span>
&lt;span style="color:#f92672">with&lt;/span>:
&lt;span style="color:#f92672">github_token&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.GITHUB_TOKEN }}&lt;/span>
&lt;span style="color:#f92672">publish_dir&lt;/span>: &lt;span style="color:#ae81ff">./public&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Use the corrected &lt;code>master&lt;/code> branch for your main branch and &lt;code>gh-pages&lt;/code> for deployment.&lt;/li>
&lt;li>Step 6: Ensure your &lt;code>hugo&lt;/code> configuration points to the correct &lt;code>baseURL&lt;/code> in &lt;code>config.toml&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-config.toml" data-lang="config.toml">&lt;span style="color:#a6e22e">baseURL&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;https://&amp;lt;username&amp;gt;.github.io/&amp;lt;repo-name&amp;gt;/&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Step 7: Run these commands below to start the workflow now.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-Terminal" data-lang="Terminal">hugo
git add .
git commit -m &amp;quot;Add GitHub Pages deployment workflow&amp;quot;
git push origin master
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Step 8: Take a breather till the actions are getting completed.&lt;/li>
&lt;li>Step 9: After the actions are completed go the same settings/ pages option and open the deployment link.(As the link you are using to read the blog)&lt;/li>
&lt;li>Step 10: Here you go your Blog site is up and running for everyone to see.ðŸ˜&lt;/li>
&lt;/ul>
&lt;h2 id="lets-summarize">Let&amp;rsquo;s Summarize&lt;/h2>
&lt;ul>
&lt;li>We write our content inside Obsidian.&lt;/li>
&lt;li>Copy this .md file into our Blogs directory using rsync/robocopy&lt;/li>
&lt;li>We create a copy of the images used in our blog to the &lt;code>static/images&lt;/code> folder using &lt;code>images.py&lt;/code>&lt;/li>
&lt;li>Now we push it to our master branch after which the &lt;code>deployment.yml&lt;/code> deploys it to our GitHub page using the &lt;code>gh-pg&lt;/code> branch.&lt;br>
Ughh the process seems so cumbersome ðŸ¤”.&lt;/li>
&lt;/ul>
&lt;h2 id="the-ultimate-python-script-for-one-command-notes--blog">The Ultimate python script for one command notes-&amp;gt; blog&lt;/h2>
&lt;ul>
&lt;li>Save the script with &lt;code>.sh&lt;/code> extension&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#75715e">#!/bin/bash
&lt;/span>&lt;span style="color:#75715e">&lt;/span>set -euo pipefail
&lt;span style="color:#75715e"># Change to the script&amp;#39;s directory&lt;/span>
SCRIPT_DIR&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>cd &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>dirname &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>BASH_SOURCE[0]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> pwd&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
cd &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$SCRIPT_DIR&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Set variables for Obsidian to Hugo copy&lt;/span>
sourcePath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;lt;source in obsidian&amp;gt;&amp;#34;&lt;/span>
destinationPath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;lt;Destination inside hugo content/blogs&amp;gt;&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Set GitHub Repo&lt;/span>
myrepo&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;reponame&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Check for required commands&lt;/span>
&lt;span style="color:#66d9ef">for&lt;/span> cmd in git rsync python3 hugo; &lt;span style="color:#66d9ef">do&lt;/span>
Â  Â  &lt;span style="color:#66d9ef">if&lt;/span> ! command -v $cmd &amp;amp;&amp;gt; /dev/null; &lt;span style="color:#66d9ef">then&lt;/span>
Â Â  Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$cmd&lt;span style="color:#e6db74"> is not installed or not in PATH.&amp;#34;&lt;/span>
Â  Â  Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
Â  Â  &lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;span style="color:#75715e"># Step 1: Check if Git is initialized, and initialize if necessary&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> ! git remote | grep -q &lt;span style="color:#e6db74">&amp;#39;origin&amp;#39;&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  git remote add origin &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$myrepo&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Remote &amp;#39;origin&amp;#39; added.&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">else&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Remote &amp;#39;origin&amp;#39; already exists.&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Step 2: Sync posts from Obsidian to Hugo content folder using rsync&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Syncing posts from Obsidian...&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> ! -d &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$sourcePath&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Source path does not exist: &lt;/span>$sourcePath&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> ! -d &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$destinationPath&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Destination path does not exist: &lt;/span>$destinationPath&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
rsync -av --delete &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$sourcePath&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$destinationPath&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Step 3: Process Markdown files with Python script to handle image links&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Processing image links in Markdown files...&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> ! -f &lt;span style="color:#e6db74">&amp;#34;images.py&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Python script images.py not found.&amp;#34;&lt;/span>
Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> ! python3 images.py; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Failed to process image links.&amp;#34;&lt;/span>
Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Step 4: Build the Hugo site&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Building the Hugo site...&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> ! hugo; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Hugo build failed.&amp;#34;&lt;/span>
Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Step 5: Add changes to Git&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Staging changes for Git...&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> git diff --quiet &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> git diff --cached --quiet; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;No changes to stage.&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">else&lt;/span>
Â  Â  git add .
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Step 6: Commit changes with a dynamic message&lt;/span>
commit_message&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;New Blog Post on &lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>date +&lt;span style="color:#e6db74">&amp;#39;%Y-%m-%d %H:%M:%S&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> git diff --cached --quiet; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;No changes to commit.&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">else&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Committing changes...&amp;#34;&lt;/span>
Â  Â  git commit -S -m &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$commit_message&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Step 7: Push all changes to the main branch&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Deploying to GitHub Master...&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> ! git push origin master; &lt;span style="color:#66d9ef">then&lt;/span>
Â  Â  echo &lt;span style="color:#e6db74">&amp;#34;Failed to push to master branch.&amp;#34;&lt;/span>
Â  Â  exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;All done! Site synced, processed, committed, built, and deployed.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Gives your script execution permission.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">chmmod +x updateblog.sh
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Now lets run the scipt.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">bash updateblog.sh
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="finally">Finally&lt;/h2>
&lt;ul>
&lt;li>Just make changes to your blog, add more blogs&lt;/li>
&lt;li>go to your terminal, run the magic command &lt;code>bash updateblog.sh&lt;/code>&lt;/li>
&lt;li>That directly puts out your content to the GitHub pages.&lt;/li>
&lt;li>Credits: Network Chuck(&lt;a href="https://youtu.be/dnE7c0ELEH8?si=ctH_oufnQeyGmUkn">https://youtu.be/dnE7c0ELEH8?si=ctH_oufnQeyGmUkn&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="be-tuned-for-more-blogs-">Be Tuned for more blogs ðŸ¤—.&lt;/h2></content></item></channel></rss>